{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на [контест](https://www.kaggle.com/c/ozon-masters-ds-contest-2021/overview)  \n",
    "\n",
    "### Используемая модель  \n",
    "Для решения данной задачи была использована модель **градиентного бустинга** библиотеки **CatBoost**.  \n",
    "- Градиентный бустинг - потому что это мощный и универсальный алгоритм машинного обучения в силу своей адаптивной техники построения композиции (грех не попробовать).  \n",
    "- CatBoost - потому что это зарекомендовавшая себя библиотека от Яндекса, реализующая градиентный бустинг над решающими деревьями, которая в сравнительном тестировании выигрывает у многих аналогов [источник](https://catboost.ai/#benchmark).\n",
    "\n",
    "### Используемые подходы  \n",
    "\n",
    "- Кодирование категориальных признаков с помощью **One-Hot Encoding** (режим игры, типы юнитов). Из плюсов: результат является двоичным, а не порядковым, модель лучше воспринимает влияние признаков в таком виде. Из минусов: это увеличивает размерность данных (в данном случае существенно, 209 (7 + 202) новых признака)\n",
    "- Удаление из исходного датасета признаков, которые незначимы (в данном случае это признаки id, X1, X3). Их незначимость проверялась экспериментально (их наличие увеличивает ошибку). Но и здравый смысл подсказывает, что они не несут в себе никакой информации для определения победителя игры\n",
    "- Подбор параметров модели (iterations, learning_rate). Learning_rate (коэффициент скорости обучения) = 0.5, т.к. это значение позволяет проходить обучению достаточно быстрыми шагами без ущерба для точности. Iterations (количество итераций) = 1000, т.к. при дальшейших итерациях значение ошибки начинает скакать и увеличиваться.\n",
    "\n",
    "### Проверялось, но не используется в конечном варианте, т.к. не дало результата  \n",
    "  \n",
    "- Замена признаков X2 и X4 (рейтингов игроков) их разностью. Т.е. гипотеза в том, что значима разница рейтингов игроков, а не сами их величины.\n",
    "- Также были испробованы другие модели машинного обучения: линейная регрессия и градиентный бустинг библиотеки sklearn, подбор оптимальных параметров, количества деревьев, но CatBoost победил в этой борьбе)\n",
    "\n",
    "### Результат  \n",
    "\n",
    "27/122 в приватном и 31/122 а публичном лидерборде "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирую категориальные признаки (режим игры и типы юнитов) с помощью one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "new_ohe_features = ohe.fit_transform(data_train.X0.values.reshape(-1,1))\n",
    "mode_values = np.sort(data_train.X0.unique())\n",
    "tmp = pd.DataFrame(new_ohe_features, columns=['mode=' + str(i) for i in mode_values])\n",
    "data_train_ohe = pd.concat([data_train, tmp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = ['X'+str(i) for i in range(5, 13)]\n",
    "units2 = ['X'+str(i) for i in range(13, 21)]\n",
    "units = units1 + units2\n",
    "for col in units1:\n",
    "    if col == units1[0]:\n",
    "        df_indic1 = pd.get_dummies(data_train_ohe[col], prefix= 'unit1_')\n",
    "    else:\n",
    "        df_indic_units1 = pd.get_dummies(data_train_ohe[col], prefix= 'unit1_')\n",
    "        df_indic1 = df_indic1 + df_indic_units1\n",
    "for col in units2:\n",
    "    if col == units2[0]:\n",
    "        df_indic2 = pd.get_dummies(data_train_ohe[col], prefix= 'unit2_')\n",
    "    else:\n",
    "        df_indic_units2 = pd.get_dummies(data_train_ohe[col], prefix= 'unit2_')\n",
    "        df_indic2 = df_indic2 + df_indic_units2 \n",
    "        \n",
    "data_train_ohe_total = pd.concat([data_train_ohe, df_indic1, df_indic2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляю ненужные признаки из обучающего датасета: целевую переменную, те признаки, которые перекодировала (в новых колонках) и те, которые незначимы (по моему мнению и по результату моих экспериментов с ними)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_ohe_total = data_train_ohe_total.drop(units, axis=1)\n",
    "data_train_ohe_total = data_train_ohe_total.drop(['id', 'X0', 'X1', 'X3', 'target'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_train_ohe_total.columns:\n",
    "    data_train_ohe_total[i] = data_train_ohe_total[i].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae33463ecb34a85bfac503a98b6cc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6712331\ttest: 0.6709367\tbest: 0.6709367 (0)\ttotal: 1.26s\tremaining: 20m 59s\n",
      "50:\tlearn: 0.6515014\ttest: 0.6513872\tbest: 0.6513872 (50)\ttotal: 45.7s\tremaining: 14m 9s\n",
      "100:\tlearn: 0.6464195\ttest: 0.6468096\tbest: 0.6468096 (100)\ttotal: 1m 28s\tremaining: 13m 6s\n",
      "150:\tlearn: 0.6432673\ttest: 0.6442510\tbest: 0.6442510 (150)\ttotal: 2m 6s\tremaining: 11m 49s\n",
      "200:\tlearn: 0.6410518\ttest: 0.6427247\tbest: 0.6427247 (200)\ttotal: 2m 43s\tremaining: 10m 48s\n",
      "250:\tlearn: 0.6392088\ttest: 0.6415055\tbest: 0.6415055 (250)\ttotal: 3m 29s\tremaining: 10m 25s\n",
      "300:\tlearn: 0.6377057\ttest: 0.6406369\tbest: 0.6406369 (300)\ttotal: 4m 13s\tremaining: 9m 49s\n",
      "350:\tlearn: 0.6363729\ttest: 0.6399717\tbest: 0.6399717 (350)\ttotal: 4m 51s\tremaining: 8m 58s\n",
      "400:\tlearn: 0.6351559\ttest: 0.6393821\tbest: 0.6393821 (400)\ttotal: 5m 29s\tremaining: 8m 12s\n",
      "450:\tlearn: 0.6340824\ttest: 0.6390260\tbest: 0.6390260 (450)\ttotal: 6m 10s\tremaining: 7m 30s\n",
      "500:\tlearn: 0.6330436\ttest: 0.6386209\tbest: 0.6386209 (500)\ttotal: 6m 48s\tremaining: 6m 46s\n",
      "550:\tlearn: 0.6321010\ttest: 0.6383659\tbest: 0.6383625 (549)\ttotal: 7m 27s\tremaining: 6m 4s\n",
      "600:\tlearn: 0.6312355\ttest: 0.6381611\tbest: 0.6381611 (600)\ttotal: 8m 5s\tremaining: 5m 22s\n",
      "650:\tlearn: 0.6304148\ttest: 0.6380002\tbest: 0.6380002 (650)\ttotal: 8m 43s\tremaining: 4m 40s\n",
      "700:\tlearn: 0.6295979\ttest: 0.6378854\tbest: 0.6378854 (700)\ttotal: 9m 23s\tremaining: 4m\n",
      "750:\tlearn: 0.6288308\ttest: 0.6378007\tbest: 0.6377804 (735)\ttotal: 10m 3s\tremaining: 3m 19s\n",
      "800:\tlearn: 0.6280954\ttest: 0.6377192\tbest: 0.6377192 (800)\ttotal: 10m 55s\tremaining: 2m 42s\n",
      "850:\tlearn: 0.6273836\ttest: 0.6376401\tbest: 0.6376311 (847)\ttotal: 11m 35s\tremaining: 2m 1s\n",
      "900:\tlearn: 0.6266737\ttest: 0.6376089\tbest: 0.6376089 (900)\ttotal: 12m 15s\tremaining: 1m 20s\n",
      "950:\tlearn: 0.6259543\ttest: 0.6375670\tbest: 0.6375566 (947)\ttotal: 12m 58s\tremaining: 40.1s\n",
      "999:\tlearn: 0.6252613\ttest: 0.6375502\tbest: 0.6375446 (985)\ttotal: 13m 42s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.637544627\n",
      "bestIteration = 985\n",
      "\n",
      "Shrink model to first 986 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ea822a5e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [i for i in range(len(data_train_ohe_total.columns))]\n",
    "cat_features.remove(0) # порядковый (уровень 1-го игрока)\n",
    "cat_features.remove(1) # порядковый (уровень 2-го игрока)\n",
    "cat_features.remove(2) # порядковый (время игры)\n",
    "\n",
    "y = data_train.target\n",
    "X = data_train_ohe_total\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=1234)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose = 50,\n",
    "    plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "new_ohe_features = ohe.fit_transform(X_test.X0.values.reshape(-1,1))\n",
    "mode_values = np.sort(X_test.X0.unique())\n",
    "tmp = pd.DataFrame(new_ohe_features, columns=['mode=' + str(i) for i in mode_values])\n",
    "data_test_ohe = pd.concat([X_test, tmp], axis = 1)\n",
    "\n",
    "for col in units1:\n",
    "    if col == units1[0]:\n",
    "        df_indic1 = pd.get_dummies(data_test_ohe[col], prefix= 'unit1_')\n",
    "    else:\n",
    "        df_indic_units1 = pd.get_dummies(data_test_ohe[col], prefix= 'unit1_')\n",
    "        df_indic1 = df_indic1 + df_indic_units1\n",
    "for col in units2:\n",
    "    if col == units2[0]:\n",
    "        df_indic2 = pd.get_dummies(data_test_ohe[col], prefix= 'unit2_')\n",
    "    else:\n",
    "        df_indic_units2 = pd.get_dummies(data_test_ohe[col], prefix= 'unit2_')\n",
    "        df_indic2 = df_indic2 + df_indic_units2 \n",
    "    \n",
    "data_test_ohe_total = pd.concat([data_test_ohe, df_indic1, df_indic2], axis = 1)\n",
    "\n",
    "data_test_ohe_total = data_test_ohe_total.drop(units, axis=1)\n",
    "data_test_ohe_total = data_test_ohe_total.drop(['id', 'X0', 'X1', 'X3'] , axis=1)\n",
    "\n",
    "for i in data_test_ohe_total.columns:\n",
    "    data_test_ohe_total[i] = data_test_ohe_total[i].astype(np.int32)\n",
    "\n",
    "cat_features = [i for i in range(len(data_test_ohe_total.columns))]\n",
    "cat_features.remove(0) # порядковый\n",
    "cat_features.remove(1) # порядковый\n",
    "cat_features.remove(2) # порядковый\n",
    "\n",
    "X_test = data_test_ohe_total\n",
    "test_pool = Pool(data=X_test, cat_features=cat_features)\n",
    "contest_predictions = model.predict_proba(test_pool)\n",
    "\n",
    "f = open('submit.csv', 'w')\n",
    "f.write('Id,target\\n')\n",
    "for idx in range(len(contest_predictions)):\n",
    "    line = str(idx) + ',' + str(round(contest_predictions[idx][1],3)) + '\\n'\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
